{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Evolutionnary Hierarchical Dirichlet Processes for Multiple Correlated Time Varying Corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------\n",
    "\n",
    "Le notebook suivant est l'implémentation du code de l'article EvoHDP, réalisé par J.Zhang,Y.Song & al et est testé sur les données synthétiques indiqués par l'article, accessible grâce au lien suivant : \n",
    "<br\\>\n",
    "http://www.shixialiu.com/publications/evohdp/paper.pdf\n",
    "<br\\> <br\\> \n",
    "Les détails et rappels mathématiques sont donnés au fur et à mesure de la rédaction du code\n",
    "\n",
    "Les références (telles que \"voir Table x\" ou \"voir (xx)\") sont celles utilisées dans l'article\n",
    "\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import os \n",
    "#from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "from scipy.stats import multinomial\n",
    "from scipy.special import gammaln\n",
    "import copy\n",
    "import math\n",
    "import mpmath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# les données sont organisées sous cette forme : data=[T][J][[doc_t_j_1],[doc_t_j_2],...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments on synthetic data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les données synthétiques sont une mixture de multinomiales, de paramètres $\\phi_k$ indiqué en Table 1 et repris ci-dessous.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true_phi=np.zeros((8,2))\n",
    "true_phi[0]=[0.1,0.9]\n",
    "true_phi[1]=[0.2,0.8]\n",
    "true_phi[2]=[0.3,0.7]\n",
    "true_phi[3]=[0.4,0.6]\n",
    "true_phi[4]=[0.5,0.5]\n",
    "true_phi[5]=[0.6,0.4]\n",
    "true_phi[6]=[0.7,0.3]\n",
    "true_phi[7]=[0.8,0.2]\n",
    "T=4\n",
    "J=3\n",
    "W=2\n",
    "K=40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0, 1, 2, 500], [1, 2, 3, 300], [2, 3, 4, 400]],\n",
       " [[1, 2, 3, 510], [2, 3, 4, 320], [3, 4, 5, 430]],\n",
       " [[2, 3, 4, 520], [3, 4, 5, 320], [4, 5, 6, 430]],\n",
       " [[3, 4, 5, 530], [4, 5, 6, 340], [5, 6, 7, 450]]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On crée un liste Info_data_sample=[T][J][local_components,size_corpora]\n",
    "corpora_sizes=[[500,300,400],[510,320,430],[520,320,430],[530,340,450]]\n",
    "def local_components_and_corpora_sizes(T,J,corpora_sizes):\n",
    "    info_data=[]\n",
    "    for t in range(T):\n",
    "        info_data_t=[]\n",
    "        for j in range(J):\n",
    "            info_data_j=[]\n",
    "            for k in range(3):\n",
    "                info_data_j.append(j+k+t)\n",
    "            info_data_j.append(corpora_sizes[t][j])\n",
    "            info_data_t.append(info_data_j)\n",
    "        info_data.append(info_data_t)   \n",
    "    return(info_data)\n",
    "info_data=local_components_and_corpora_sizes(T,J,corpora_sizes)\n",
    "info_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mixture_of_three_multinomial(liste_of_phi_indices,true_phi,corpora_size,z):\n",
    "    \n",
    "    mult1=np.random.multinomial(200,true_phi[liste_of_phi_indices[0]],size=z[0]).tolist()\n",
    "    mult2=np.random.multinomial(200,true_phi[liste_of_phi_indices[1]],size=z[1]).tolist()\n",
    "    mult3=np.random.multinomial(200,true_phi[liste_of_phi_indices[2]],size=z[2]).tolist()\n",
    "    mixt_mult_float=np.concatenate((np.concatenate((mult1,mult2),axis=0),mult3),axis=0)\n",
    "    #print(mixt_mult_float)\n",
    "    mixt_mult_int=[[mixt_mult_float[t][j].tolist() for j in range(len(mixt_mult_float[t]))] for t in range(len(mixt_mult_float))]\n",
    "    return(mixt_mult_int)\n",
    "\n",
    "def generate_data_from_mixture_of_multinomials(T,J,info_data,true_phi):\n",
    "    data=[]\n",
    "    for t in range(T):\n",
    "        data_t=[]\n",
    "        for j in range(J):\n",
    "            z=np.random.multinomial(info_data[t][j][3],[1/3,1/3,1/3])           \n",
    "            doc_t_j=mixture_of_three_multinomial(info_data[t][j],true_phi,info_data[t][j][3],z)\n",
    "            data_t.append(doc_t_j)\n",
    "        #data_t.append(data_j)\n",
    "        data.append(data_t)\n",
    "    return(data)\n",
    "data=generate_data_from_mixture_of_multinomials(T,J,info_data,true_phi)\n",
    "#data=[T][J][[doc_t_j_1],[doc_t_j_2],...]\n",
    "#data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objectif de cette expérimentation est de retrouver les \"true_phi\" par l'algorithme EvoHDP. Ces \"true_phi\" ont été utilisé pour générer nos données. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize hyper parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour l'initialisation le modèle est celui d'un HDP à trois niveaux :\n",
    "\n",
    "$$ H \\sim Dir ( 1/W) $$ \n",
    "$$ G \\sim DP(\\xi , H) $$\n",
    "\n",
    "Pour chaque temps :\n",
    "\n",
    "$$ \\forall t \\in T $$\n",
    "$$ G_{0}^t \\sim DP(\\gamma^t , G) $$\n",
    "\n",
    "Pour chaque corpus : \n",
    "\n",
    "$$ \\forall j \\in J $$\n",
    "$$ G_{j}^t \\sim DP(\\alpha_{0}^t , G_{0}^t) $$\n",
    "\n",
    "\n",
    "On doit simuler pour l'inititalisation des paramètres :\n",
    "$$ \\xi \\sim Gamma(10,1) $$ \n",
    "Pour chaque temps : \n",
    "$$ \\forall t \\in T $$\n",
    "$$ \\eta^t \\sim Gamma(10,1) $$\n",
    "$$ \\alpha_{0}^t \\sim Gamma(10,1) $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\xi \\sim Gamma(10,1) $$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_xi=10\n",
    "b_xi=1\n",
    "xi=np.random.gamma(a_xi,b_xi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour chaque temps : \n",
    "$$ \\forall t \\in T $$\n",
    "$$ \\gamma^t \\sim Gamma(10,1) $$\n",
    "$$ \\alpha_{0}^t \\sim Gamma(10,1) $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_gamma=10\n",
    "b_gamma=1\n",
    "a_alpha=10\n",
    "b_alpha=1\n",
    "\n",
    "gamma=[np.random.gamma(a_gamma,b_gamma) for i in range(T)]\n",
    "alpha=[np.random.gamma(a_alpha,b_alpha) for i in range(T)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On crée les time dependencies $v^t=w^t=a$ avec $a \\in {0.1,0.3,0.5,0.7,0.9}$ et nous étudierons l'impact de cette variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ici a=0.8\n",
    "v=T*[K*[0.8]]\n",
    "w=T*[0.8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate from stick breaking for initilization of measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ H \\sim Dir ( 1/W) $$ \n",
    "$$ G \\sim DP(\\xi , H) $$\n",
    "\n",
    "$$ G = \\sum_{k=1}^{\\infty} \\nu_k \\delta_{\\phi_k} $$\n",
    "où : \n",
    "$$ \\nu \\sim GEM(\\xi) $$ et: $$ \\phi_k \\sim H $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stick_breaking(alpha, k, size_W):\n",
    "    if(alpha < 0): return(\"alpha must be positive\")\n",
    "    betas = np.random.beta(1, alpha, k)\n",
    "    produit_1_beta = np.append(1, np.cumprod(1 - betas[:-1]))\n",
    "    p = betas * produit_1_beta\n",
    "    return(p/p.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.14658528, 0.00871645, 0.06372991, 0.14410922, 0.02202676,\n",
       "       0.0602664 , 0.03323348, 0.00200815, 0.03447794, 0.01375054,\n",
       "       0.00476713, 0.02726176, 0.05403558, 0.04220598, 0.08828288,\n",
       "       0.06292217, 0.00984795, 0.01770217, 0.00202228, 0.01543361,\n",
       "       0.01737794, 0.00057692, 0.00261938, 0.01184933, 0.01907498,\n",
       "       0.00441182, 0.02183275, 0.01773072, 0.01177025, 0.00655598,\n",
       "       0.00596444, 0.0016819 , 0.00364075, 0.00078156, 0.00152781,\n",
       "       0.00465845, 0.00204558, 0.00221279, 0.01013686, 0.00016417])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nu=stick_breaking(xi,K,W)\n",
    "nu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ G = \\sum_{k=1}^{\\infty} \\nu_k \\delta_{\\phi_k} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois G simulé, on sait que :\n",
    "$$ G_{0}^t = Dir( \\gamma^{t} , G) $$\n",
    "D'après l'approche stick breaking :\n",
    "$$ G_{0}^t = \\sum_{k=1}^\\infty \\beta_{k}^t\\delta_{\\phi_k} $$\n",
    "où\n",
    "$$ \\beta^t \\sim DP(\\gamma^t,\\hat{\\beta}^t)$$$$\\hat{\\beta}^t=w^t\\beta^{t-1}+(1-w^t)\\nu$$$$  \\nu\\sim GEM(\\xi) $$ \n",
    "Pour simuler $ G_{0}^t$, on défini les deux propriétés suivantes : <br/> <br/>\n",
    "I. D'après la **propriété de normalisation**  d'un processus de Dirichlet: <br/><br/>\n",
    "**Si** $$ (X_1,...,X_d)\\sim Dirichlet(\\alpha_1,...,\\alpha_d) $$\n",
    "**Alors, pour k $\\leq$ d**\n",
    "$$ \\dfrac{(X_1,...,X_k)}{\\sum_{i\\leq k}X_i} \\sim Dirichlet(\\alpha_1,...,\\alpha_k) $$\n",
    "<br/><br/>\n",
    "II. Lien entre **la loi de Dirichlet et la loi Beta**:<br/><br/>\n",
    "**Si** $$(X_1,...,X_d)\\sim Dir(\\alpha_1,...,\\alpha_d)$$ \n",
    "**Alors** $$\\forall i \\in [1,d],\n",
    "X_i \\sim Beta(\\alpha_i,\\alpha-\\alpha_i),\\alpha=\\sum_{j=1}^d\\alpha_j$$ <br/><br/>\n",
    "\n",
    "Ainsi on a : <br/>\n",
    "$$ \\frac{\\beta_k^t}{1-\\sum_{i<k}\\beta_i^t} \\sim Beta(\\gamma^t\\hat{\\beta}_k,\\gamma^t(1-\\sum_{i\\leq k}\\hat{\\beta}_i))$$<br/>\n",
    "Stick-Breaking donne :\n",
    "$$ \\tilde{\\beta_k^t}/\\hat{\\beta}_1,...,\\hat{\\beta}_k  \\sim Beta(\\gamma^t\\hat{\\beta}_k,\\gamma^t(1-\\sum_{i\\leq k}\\hat{\\beta}_i)) $$ i<=k pose problème pour la dernière simulation du K. Du au fait que K est fixé\n",
    "$$ \\beta_k^t=\\tilde{\\beta_k^t}\\prod_{i<k}(1-\\tilde{\\beta_i^t})$$<br\\><br\\>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Propriété des lois Beta/Dirichlet pour d=2** <br\\><br\\>\n",
    "Si $$(X_1,X_2)\\sim Dirichlet(\\alpha,\\beta)$$ alors $$X_1 \\sim Beta(\\alpha,\\beta)$$\n",
    "On se sert PAS ENCORE de cette propriété dans la fonction pour simuler selon une dirichlet au lieu d'une Beta\n",
    "<br\\><br\\> \n",
    "Dans les fonctions suivantes, on peut avoir besoin de la fonction np.random.dirichlet pour simuler nos nouveaux paramètres.\n",
    "Cette fonction nécéssite que le vecteur donné en paramètre ait des valeurs >0 ce qui n'est pas forcément le cas. <br\\> Pour vérifier cette condition, on crée la fonction suivante : \"dirichlet_generate_random\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dirichlet_generate_random(params_dirich):\n",
    "    if(type(params_dirich)==list):\n",
    "        params_dirich=np.array(params_dirich)\n",
    "    liste_indice_non_zero=np.nonzero(params_dirich)\n",
    "    param_non_zero=params_dirich[params_dirich>0]\n",
    "    rand_dir=np.random.dirichlet(param_non_zero)\n",
    "    random_finale=np.zeros((len(params_dirich)))\n",
    "    random_finale[liste_indice_non_zero]=rand_dir\n",
    "    return(random_finale)\n",
    "\n",
    "def beta_generate_random(params_beta):\n",
    "    if(type(params_beta)==list):\n",
    "        params_beta=np.array(params_beta)\n",
    "    if(len(params_beta)!=2):\n",
    "        print(\"ERROR, la taille des paramètres pour la simluation d'une beta est supérieur à 2\")\n",
    "    if(params_beta[0]<=0):\n",
    "        return(0)\n",
    "    if(params_beta[1]<=0):\n",
    "        return(1)\n",
    "    random_final=np.random.beta(params_beta[0],params_beta[1])\n",
    "    return(random_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# voir (8)\n",
    "def initialize_G_0_t (gamma,nu,T,K,w):\n",
    "    G_0_t=[]\n",
    "    for t in range(T):\n",
    "        if(t==0):\n",
    "            beta_t=[]\n",
    "            beta_tilde_t=[]\n",
    "            for k in range(K):\n",
    "                params_dirich=[gamma[t]*nu[k],gamma[t]*(1-np.sum(nu[:k+1]))]\n",
    "                beta_tilde_k_t=beta_generate_random(params_dirich)\n",
    "                beta_tilde_t.append(beta_tilde_k_t)\n",
    "                beta_k_t=beta_tilde_k_t*np.product(1-np.array(beta_tilde_t[:k]))\n",
    "                beta_t.append(beta_k_t)\n",
    "            G_0_t.append((beta_t/np.sum(beta_t)).tolist())\n",
    "        else:        \n",
    "            beta_t=[]\n",
    "            beta_tilde_t=[]\n",
    "            beta_hat=w[t]*np.array(G_0_t[t-1])+(1-w[t])*nu\n",
    "            for k in range(K):\n",
    "                params_dirich=[gamma[t]*beta_hat[k],gamma[t]*(1-np.sum(beta_hat[:k+1]))]\n",
    "                beta_tilde_k_t=beta_generate_random(params_dirich)\n",
    "                beta_tilde_t.append(beta_tilde_k_t)\n",
    "                beta_k_t=beta_tilde_k_t*np.product(1-np.array(beta_tilde_t[:k]))\n",
    "                beta_t.append(beta_k_t)\n",
    "            G_0_t.append((beta_t/np.sum(beta_t)).tolist())\n",
    "    return(G_0_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beta=initialize_G_0_t (gamma,nu,T,K,w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, on simule $G_j^t$ $$ \\forall t \\in T, \\forall j \\in J$$  \n",
    "$$ G_j^t=\\sum_{k=1}^{\\infty}\\pi_{jk}^t\\delta_{\\phi_k}$$ $$\\pi_j^t\\sim DP(\\alpha_0^t,\\hat{\\pi}^t_j)$$\n",
    "\n",
    "$$\\hat{\\pi}^t_j=v_j^t\\pi_j^{t-1}+(1-v_j^t)\\beta^t$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#voir (9)\n",
    "def initialize_G_j_t (G_0_t,alpha,J,T,K,v):\n",
    "    G_j_T=[]\n",
    "    for t in range(T):\n",
    "        G_j_t=[]\n",
    "        if(t==0):\n",
    "            for j in range(J):\n",
    "                alpha_j_t=[]\n",
    "                alpha_tilde_j_t=[]\n",
    "                for k in range(K):\n",
    "                    params_dirich=[alpha[t]*G_0_t[t][k],alpha[t]*(1-np.sum(G_0_t[t][:k+1]))]\n",
    "                    alpha_tilde_k_t=beta_generate_random(params_dirich)\n",
    "                    alpha_tilde_j_t.append(alpha_tilde_k_t)\n",
    "                    alpha_k_t=alpha_tilde_k_t*np.product(1-np.array(alpha_tilde_j_t[:k]))\n",
    "                    alpha_j_t.append(alpha_k_t)     \n",
    "                G_j_t.append((alpha_j_t/(np.sum(alpha_j_t))).tolist())\n",
    "            G_j_T.append(G_j_t)\n",
    "        else:\n",
    "            for j in range(J):\n",
    "                alpha_j_t=[]\n",
    "                alpha_tilde_j_t=[]\n",
    "                alpha_hat=v[t][j]*np.array(G_j_T[t-1][j])+(1-v[t][j])*np.array(G_0_t[t][k])\n",
    "                for k in range(K):\n",
    "                    params_dirich=[alpha[t]*alpha_hat[k],alpha[t]*(1-np.sum(alpha_hat[:k+1]))]\n",
    "                    alpha_tilde_k_t=beta_generate_random(params_dirich)\n",
    "                    alpha_tilde_j_t.append(alpha_tilde_k_t)\n",
    "                    alpha_k_t=alpha_tilde_k_t*np.product(1-np.array(alpha_tilde_j_t[:k]))\n",
    "                    alpha_j_t.append(alpha_k_t)     \n",
    "                G_j_t.append((alpha_j_t/(np.sum(alpha_j_t))).tolist())\n",
    "            G_j_T.append(G_j_t)\n",
    "    return(G_j_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pi=initialize_G_j_t(beta,alpha,J,T,K,v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois qu'on a initialisé les $$\\pi_{jk}^t$$ \n",
    "On initialise randomly les Z\n",
    "\n",
    "La fonction \"compute_Z_j_t\" permet de calculer les probas normalisées d'un doc au temps t, pour le corpus j.<br/>\n",
    "La fonction \"compute_proba_z_i_j_t_is_k\" étend ce calcul à tous les temps et corpus.<br/>\n",
    "La fonction \"log_proba_mult\" n'est pas utilisée mais peut s'avérer utile pour éviter les arrondis.<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/> Pour l'initialisation, Z est calculé sans information à posteriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def randomly_assign_Z_initialisation(T,J,K,data):\n",
    "    Z=[]\n",
    "    n=[]\n",
    "    for t in range(T):\n",
    "        Z_t=[]\n",
    "        n_t=[]\n",
    "        for j in range(J):\n",
    "            Z_t_j=list(np.nonzero(np.random.multinomial(1,[1/K]*K,len(data[t][j])))[1])\n",
    "            Z_t.append(Z_t_j)\n",
    "            n_t.append(compute_n_t_j(K,Z_t_j))\n",
    "        Z.append(Z_t)\n",
    "        n.append(n_t)\n",
    "    return(Z,n)\n",
    "Z,N=randomly_assign_Z_initialisation(T,J,K,data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut maintenant obtenir $n_{jk}^t$ qui est le nombre de documents du corpus j au temps t qui ont été assignés au topic k (i.e # $z_{ij}^t$ : $z_{ij}^t=k$) <br/> \n",
    "La fonction \"compute_n_t_j\" calcule $n_{jk}^t, \\forall k \\in K$ et retourne une liste de taille K "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_n_t_j(K,liste_des_Z_temps_t_corpus_j):\n",
    "    n_t_j=[]\n",
    "    for k in range(K):\n",
    "        n_t_j.append(liste_des_Z_temps_t_corpus_j.count(k))\n",
    "    return(n_t_j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction \"compute_T_jk_t_tplus1_et_T_jk_0_tplus1_multinomiale\" calule :   <br\\> <br\\> $$(T_{jk}^{t \\Rightarrow t+1},T_{jk}^{0 \\Rightarrow t+1}) \\sim Multinomiale (T_{jk}^{t+1},[p,1-p]),(22)$$  <br\\> avec $$p=\\frac{v_j^{t+1}\\pi_{jk}^t}{(1-v_j^{t+1})\\beta_k^{t+1} + v_j^{t+1}\\pi_{jk}^t} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_T_jk_t_tplus1_et_T_jk_0_tplus1_multinomiale(T_jk_Tplus1,v_j_Tplus1,pi_jk_t,beta_k_Tplus1):\n",
    "    if(((1-v_j_Tplus1)*beta_k_Tplus1+v_j_Tplus1*pi_jk_t)!=0):\n",
    "        p=(v_j_Tplus1*pi_jk_t)/((1-v_j_Tplus1)*beta_k_Tplus1+v_j_Tplus1*pi_jk_t)\n",
    "    else:\n",
    "        p=0\n",
    "    T_jk_t_tplus1,T_jk_0_tplus1=np.random.multinomial(T_jk_Tplus1, [p,1-p])\n",
    "    return(T_jk_t_tplus1,T_jk_0_tplus1)\n",
    "\n",
    "def compute_M_jk_t_tplus1_et_M_jk_0_tplus1_multinomiale(M_k_Tplus1,w_Tplus1,beta_k_t,nu_k):\n",
    "    if(((1-w_Tplus1)*nu_k+w_Tplus1*beta_k_t)!=0):\n",
    "        q=(w_Tplus1*beta_k_t)/(((1-w_Tplus1)*nu_k)+(w_Tplus1*beta_k_t))\n",
    "    else:\n",
    "        q=0\n",
    "    M_k_t_tplus1,Mk_0_tplus1=np.random.multinomial(M_k_Tplus1, [q,1-q])\n",
    "    return(M_k_t_tplus1,Mk_0_tplus1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ N_{jk}^t=n_{jk}^t+T_{jk}^{t \\Rightarrow t+1}$$\n",
    "$n_{jk}^t$ est le nombre de document du corpus j assignés au topic k au temps t <br\\>\n",
    "$T_{jk}^{t \\Rightarrow t+1}$ est le nombre de tables qui ont été crées avec les menus du temps t. <br\\><br\\>\n",
    "Pour estimer $T_{jk}^t$, on a besoin du plus d'informations sur cette variables, soit le nombre de documents constituant ce topic, et le nombre de tables qui par la suite ont été considérée comme issue de notre résultat et transmises au temps d'après.<br\\><br\\>\n",
    "Ex: si 300 documents sont dans le topic k, et que 40tables issues de notre résultats ont été transmises au temps d'après, on peut penser que beaucoup de tables sont nécéssaire pour représenter le topic k. La valeur de $ N_{jk}^t$ étant grande (car = 340), le CRP défini ci dessous génèrera beaucoup de tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ T_{jk}^t/\\beta_k^t,\\pi_{jk}^{t-1},N_{jk}^t\\sim   CRP   (\\alpha_0^t v_j^t\\pi_{jk}^{t-1} + \\alpha_0^t(1- v_j^t)\\beta_k^t,N_{jk}^t)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate table assignments for `num_customers` customers, according to\n",
    "# a Chinese Restaurant Process with dispersion parameter `alpha`.\n",
    "def chinese_restaurant_process(num_customers, alpha):\n",
    "    if (num_customers <= 0 or alpha<0) :\n",
    "        return(0)\n",
    "    elif(alpha==0):\n",
    "        #print(\"alpha == 0\")\n",
    "        return(0)\n",
    "    else :\n",
    "        T_jk_t=0\n",
    "        for i in range(num_customers):        \n",
    "            if(np.random.rand()<alpha/(alpha+i)):\n",
    "                T_jk_t+=1\n",
    "    return(T_jk_t)\n",
    "T_jk_t=chinese_restaurant_process(100,15)   \n",
    "\n",
    "#num_customers=248\n",
    "#alpha_test=alpha[0]\n",
    "#T_jk_t=chinese_restaurant_process(num_customers,alpha_test)\n",
    "#T_jk_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction suivante retourne une liste (dim K) de listes (dim 3) contenant  : $$T_{jk}^{t\\Rightarrow t+1},T_{jk}^{0\\Rightarrow t+1},T_{jk}^t$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_T_tP1_T_0t_Tjkt(temps0,tempsT,T_jk_ttp1,n_jk_t,v_j_t,pi_jk_T_moins1,beta_k_T,alpha_t):\n",
    "    T_3=[]\n",
    "    Nu=[]\n",
    "    if(temps0):\n",
    "        for k in range(len(n_jk_t)):\n",
    "            Nu_jk_t=n_jk_t[k]+T_jk_ttp1[k]\n",
    "            Nu.append(Nu_jk_t)\n",
    "            param_CRP=(alpha_t*beta_k_T[k])\n",
    "            T_0_jk=chinese_restaurant_process(Nu_jk_t,param_CRP)\n",
    "            T_3.append([0,T_0_jk,T_0_jk])\n",
    "    elif(tempsT):\n",
    "        for k in range(len(n_jk_t)):\n",
    "            Nu_jk_t=n_jk_t[k]\n",
    "            Nu.append(Nu_jk_t)\n",
    "            param_CRP=(alpha_t*v_j_t[k]*pi_jk_T_moins1[k])+(alpha_t*(1-v_j_t[k])*beta_k_T[k])\n",
    "            T_0_jk=chinese_restaurant_process(Nu_jk_t,param_CRP)\n",
    "            T_jk_t_tplus1,T_jk_0_tplus1=compute_T_jk_t_tplus1_et_T_jk_0_tplus1_multinomiale(T_0_jk,v_j_t[k],pi_jk_T_moins1[k],beta_k_T[k])\n",
    "            T_3.append([T_jk_t_tplus1,T_jk_0_tplus1,T_0_jk])\n",
    "    else:\n",
    "        for k in range(len(n_jk_t)):\n",
    "            Nu_jk_t=n_jk_t[k]+T_jk_ttp1[k]\n",
    "            Nu.append(Nu_jk_t)\n",
    "            param_CRP=(alpha_t*v_j_t[k]*pi_jk_T_moins1[k])+(alpha_t*(1-v_j_t[k])*beta_k_T[k])\n",
    "            T_0_jk=chinese_restaurant_process(Nu_jk_t,param_CRP)\n",
    "            T_jk_t_tplus1,T_jk_0_tplus1=compute_T_jk_t_tplus1_et_T_jk_0_tplus1_multinomiale(T_0_jk,v_j_t[k],pi_jk_T_moins1[k],beta_k_T[k])\n",
    "            T_3.append([T_jk_t_tplus1,T_jk_0_tplus1,T_0_jk])\n",
    "    return(T_3,Nu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les fonctions suivantes calculent les Métatables :\n",
    "<br/> <br/> La dimension de Métatable est une liste : T*K*3\n",
    "\n",
    "La fonction \"compute_T_jk_t_tplus1_et_T_jk_0_tplus1_multinomiale\" calule :   <br\\> <br\\> $$(M_{k}^{t \\Rightarrow t+1},M_{k}^{0 \\Rightarrow t+1}) \\sim Multinomiale (M_{k}^{t+1},[q,1-q]),(25)$$  <br\\> avec $$q=\\frac{w^{t+1}\\beta_{k}^t}{(1-w^{t+1})\\nu_k + w^{t+1}\\beta{k}^t} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_M_tP1_T_0t_Tjkt(t,temps0,tempsT,M_k_ttp1,Tables,w_t,beta_tmoins1_k,gamma_t,nu,K):\n",
    "    M_3=[]\n",
    "    Tau=[]\n",
    "    if(temps0):\n",
    "        for k in range(K):\n",
    "            Tau_t_k=np.sum(np.array(Tables)[t,:,k,1])+M_k_ttp1[k]\n",
    "            Tau.append(Tau_t_k)\n",
    "            param_CRP=(gamma_t*nu[k])\n",
    "            M_tk=chinese_restaurant_process(Tau_t_k,param_CRP)\n",
    "            M_3.append([0,M_tk,M_tk])\n",
    "    elif(tempsT):\n",
    "        for k in range(K):\n",
    "            Tau_t_k=np.sum(np.array(Tables)[t,:,k,1])\n",
    "            Tau.append(Tau_t_k)\n",
    "            param_CRP=(gamma_t*w_t*beta_tmoins1_k[k])+(gamma_t*(1-w_t)*nu[k])\n",
    "            M_tk=chinese_restaurant_process(Tau_t_k,param_CRP)\n",
    "            M_jk_t_tplus1,M_jk_0_tplus1=compute_M_jk_t_tplus1_et_M_jk_0_tplus1_multinomiale(M_tk,w_t,beta_tmoins1_k[k],nu[k])\n",
    "            M_3.append([M_jk_t_tplus1,M_jk_0_tplus1,M_tk])\n",
    "    else:\n",
    "        for k in range(K):\n",
    "            Tau_t_k=np.sum(np.array(Tables)[t,:,k,1])+M_k_ttp1[k]\n",
    "            Tau.append(Tau_t_k)\n",
    "            param_CRP=(gamma_t*w_t*beta_tmoins1_k[k])+(gamma_t*(1-w_t)*nu[k])\n",
    "            M_tk=chinese_restaurant_process(Tau_t_k,param_CRP)\n",
    "            M_jk_t_tplus1,M_jk_0_tplus1=compute_M_jk_t_tplus1_et_M_jk_0_tplus1_multinomiale(M_tk,w_t,beta_tmoins1_k[k],nu[k])\n",
    "            M_3.append([M_jk_t_tplus1,M_jk_0_tplus1,M_tk])\n",
    "    return(M_3,Tau)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_Tables_Metatables(T,J,v,w,pi,beta,alpha,gamma,nu,n,K):\n",
    "    Table=[]\n",
    "    MetaTable=[]\n",
    "    Nu=[]\n",
    "    for t in range(T-1,-1,-1):\n",
    "        T_t=[]\n",
    "        Nu_t=[]\n",
    "        temps_info=t\n",
    "        if (temps_info==T-1): \n",
    "            for j in range(J):\n",
    "                T_tj,Nu_t_j=compute_T_tP1_T_0t_Tjkt(0,1,0,n[t][j],v[t],pi[t-1][j],beta[t],alpha[t])\n",
    "                T_t.append(T_tj)\n",
    "                Nu_t.append(Nu_t_j)\n",
    "        elif(temps_info==0):\n",
    "            for j in range(J):\n",
    "                T_tj,Nu_t_j=compute_T_tP1_T_0t_Tjkt(1,0,np.array(Table)[T-t-2,j,:,0],n[t][j],v[t],0,beta[t],alpha[t])\n",
    "                T_t.append(T_tj)\n",
    "                Nu_t.append(Nu_t_j)\n",
    "        else:\n",
    "            for j in range(J):\n",
    "                T_tj,Nu_t_j=compute_T_tP1_T_0t_Tjkt(0,0,np.array(Table)[T-t-2,j,:,0],n[t][j],v[t],pi[t-1][j],beta[t],alpha[t])\n",
    "                Nu_t.append(Nu_t_j)\n",
    "                T_t.append(T_tj)   \n",
    "        Table.append(T_t)\n",
    "        Nu.append(Nu_t)\n",
    "    Nu=Nu[::-1]\n",
    "    Table=Table[::-1]\n",
    "    Tau=[]\n",
    "    for t in range(T-1,-1,-1):\n",
    "        temps_info=t\n",
    "        if (temps_info==T-1):\n",
    "            M_t,Tau_t=compute_M_tP1_T_0t_Tjkt(t,0,1,0,Table,w[t],beta[t-1],gamma[t],nu,K)\n",
    "            MetaTable.append(M_t)\n",
    "            Tau.append(Tau_t)\n",
    "        elif(temps_info==0):\n",
    "            M_t,Tau_t=compute_M_tP1_T_0t_Tjkt(t,1,0,np.array(MetaTable)[T-2-t,:,0],Table,w[t],0,gamma[t],nu,K)\n",
    "            MetaTable.append(M_t)\n",
    "            Tau.append(Tau_t)\n",
    "        else:\n",
    "            M_t,Tau_t=compute_M_tP1_T_0t_Tjkt(t,0,0,np.array(MetaTable)[T-2-t,:,0],Table,w[t],beta[t-1],gamma[t],nu,K)\n",
    "            MetaTable.append(M_t)\n",
    "            Tau.append(Tau_t)\n",
    "    Tau=Tau[::-1]\n",
    "    MetaTable=MetaTable[::-1]\n",
    "    return(Table,MetaTable,Tau,Nu)\n",
    "            \n",
    "Tables,MetaTable,Tau,Nu=compute_Tables_Metatables(T,J,v,w,pi,beta,alpha,gamma,nu,N,len(beta[1])) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling $\\nu$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois les Tables et Metatables calculés, on va réapproximer les poids. <br/> <br/> $$M_k = \\sum_t M_{k}^t$$\n",
    "<br/> $$M = \\sum_k M_{k}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$G/\\xi,H,( M_k )_{k=1}^{K} \\sim DP(\\xi+M,\\frac{H+\\sum_{k=1}^K M_k \\delta_{\\phi_k}}{\\xi + M})$$\n",
    "où K est le nombre de plats distincts sur toutes les métatables. On peut représenter G de la façon suivante :\n",
    "$$ G = \\sum_{k=1}^K \\nu_k \\delta_{\\phi_k} + \\nu_u G_u$$$$ G_u\\sim DP(\\xi,H) $$$$ \\nu=(\\nu_1,...,\\nu_K,\\nu_u)\\sim Dirichlet(M_1,...,M_K,\\xi)$$ <br\\>On simule donc $\\nu$ selon une loi de dirichlet de paramètres $M_1,...,M_k,M_u$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calcul de $\\beta$ ** <br\\>\n",
    "Une fois qu'on a réduit les dimensions de nos objets et conservé seulement les topics intéressants, on sample $\\beta^t$ selon 14 <br\\> \n",
    "$$(\\beta_u^t,\\beta_1^t,...,\\beta_K^t)\\sim Dirichlet(\\tilde{\\gamma^t}.(\\tilde{\\beta_u^t},\\tilde{\\beta_1^t},...,\\tilde{\\beta_K^t}))$$ avec \n",
    "\n",
    "$$\\tilde{\\gamma^t}=\\gamma^t+  TAU^t_.$$ et \n",
    "$$ \\tilde{\\beta_k^t} = \\frac{1}{\\tilde{\\gamma^t}}(\\gamma^t w^t \\beta_k^{t-1} + \\gamma^t(1 - w^t)\\nu_k+ TAU^t_k)$$\n",
    "\n",
    "<br\\>\n",
    "et\n",
    "<br\\>\n",
    "\n",
    "$$ \\tilde{\\beta_u^t} = \\frac{1}{\\tilde{\\gamma^t}}(\\gamma^t w^t \\beta_u^{t-1} + \\gamma^t(1 - w^t)\\nu_u)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tau et Nu sont calculés plus haut, on s'en sert pour calculé les tildes <br\\> Les fonctions suivantes calculent respectivement, $\\tilde{\\gamma}$ , $\\tilde{\\beta}$ et $\\beta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gamma_tilde(gamma,Tau):\n",
    "    gamma_tilde=gamma+np.sum(np.array(Tau),axis=1)\n",
    "    return(gamma_tilde)\n",
    "#gamma_tilde=compute_gamma_tilde(gamma,Tau)\n",
    "\n",
    "\n",
    "def compute_beta_t_tilde(t,gamma_t,gamma_tilde_t,w_t,beta_tmoins1,nu,tau_t):\n",
    "    beta_t_tilde=[]\n",
    "    if(t!=0):\n",
    "        for k in range(len(nu)-1):\n",
    "            if(gamma_tilde_t>0):\n",
    "                beta_t_k_tilde=(1/gamma_tilde_t)*((gamma_t*w_t*beta_tmoins1[k])+(gamma_t*(1-w_t)*nu[k]+tau_t[k]))\n",
    "                beta_t_tilde.append(beta_t_k_tilde)\n",
    "            else:\n",
    "                beta_t_tilde.append(0) \n",
    "        if(gamma_tilde_t>0):\n",
    "            beta_t_u_tilde=(1/gamma_tilde_t)*((gamma_t*w_t*beta_tmoins1[len(nu)-1])+(gamma_t*(1-w_t)*nu[len(nu)-1]))\n",
    "            beta_t_tilde.append(beta_t_u_tilde)\n",
    "        else: \n",
    "            beta_t_tilde.append(0) \n",
    "    else:\n",
    "        for k in range(len(nu)-1):\n",
    "            if(gamma_tilde_t):\n",
    "                beta_t_k_tilde=(1/gamma_tilde_t)*(gamma_t*nu[k]+tau_t[k])\n",
    "                beta_t_tilde.append(beta_t_k_tilde)\n",
    "            else:\n",
    "                beta_t_tilde.append(0)  \n",
    "        if(gamma_tilde_t):        \n",
    "            beta_t_u_tilde=(1/gamma_tilde_t)*(gamma_t*nu[len(nu)-1])\n",
    "            beta_t_tilde.append(beta_t_u_tilde)\n",
    "        else:\n",
    "            beta_t_tilde.append(0)  \n",
    "\n",
    "    return(beta_t_tilde)\n",
    "\n",
    "def compute_new_beta(gamma,w,nu,tau):\n",
    "    beta_new=[]\n",
    "    gamma_tilde=compute_gamma_tilde(gamma,tau)\n",
    "    for t in range(len(gamma_tilde)):\n",
    "        if(t==0):\n",
    "            beta_t_tilde=compute_beta_t_tilde(t,gamma[t],gamma_tilde[t],w[t],None,nu,tau[t])\n",
    "        else:\n",
    "            beta_t_tilde=compute_beta_t_tilde(t,gamma[t],gamma_tilde[t],w[t],beta_new[t-1],nu,tau[t])\n",
    "        params_dirich=gamma_tilde[t]*np.array(beta_t_tilde)\n",
    "        beta_t=dirichlet_generate_random(params_dirich)\n",
    "        beta_new.append(beta_t.tolist())\n",
    "    return(beta_new)\n",
    "new_beta=compute_new_beta(gamma,w,nu,Tau)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calcul de $\\pi$ ** <br\\>\n",
    "De même que pour $\\beta$, on calcule $\\pi$ de ma façon suivante : <br\\>\n",
    "\n",
    "$$(\\pi_{ju}^t,\\pi_{j1}^t,...,\\pi_{jK}^t)\\sim Dirichlet(\\tilde{\\alpha_{0j}^t}.(\\tilde{\\pi_{ju}^t},\\tilde{\\pi_{j1}^t},...,\\tilde{\\pi_{jK}^t}))$$ avec \n",
    "\n",
    "$$\\tilde{\\alpha}_{0j}^t=\\alpha_0^t+  N^t_{j.}$$ et \n",
    "$$ \\tilde{\\pi_{jk}^t} = \\frac{1}{\\tilde{\\alpha_0^t}}(\\alpha_0^t v^t \\pi_{jk}^{t-1} + \\alpha_0^t(1 - v^t)\\beta_k^t+ N^t_{jk})$$\n",
    "\n",
    "<br\\>\n",
    "et\n",
    "<br\\>\n",
    "\n",
    "$$ \\tilde{\\pi_{ju}^t} = \\frac{1}{\\tilde{\\alpha_0^t}}(\\alpha_0^t v^t \\pi_{jk}^{t-1} + \\alpha_0^t(1 - v^t)\\beta_k^t$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8.739978679119929, 13.893627767292376, 10.208622578992674, 8.515180027421113]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.array(Nu)[:,1,:],axis=1)\n",
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "def compute_alpha_tilde(alpha,Nu):\n",
    "    alpha_tilde=[]\n",
    "    for j in range(len(Nu[0])):\n",
    "        alpha_tilde.append((alpha+np.sum(np.array(Nu)[:,j,:],axis=1)).tolist())\n",
    "    alpha_tilde=np.transpose(np.array(alpha_tilde))\n",
    "    return(alpha_tilde.tolist())\n",
    "#alpha_tilde=compute_alpha_tilde(alpha,Nu)\n",
    "\n",
    "def compute_pi_t_j_tilde(t,j,alpha_0_t,alpha_0_t_tilde,v_t,pi_tmoins1_j,beta_t,Nu_t_j):\n",
    "    pi_t_j_tilde=[]\n",
    "    if(t!=0):\n",
    "        for k in range(len(beta_t)-1):\n",
    "            if(alpha_0_t_tilde>0):\n",
    "                pi_t_j_tilde_k=(1/alpha_0_t_tilde)*(alpha_0_t*v_t[k]*pi_tmoins1_j[k]+alpha_0_t*(1-v_t[k])*beta_t[k]+Nu_t_j[k])\n",
    "                pi_t_j_tilde.append(pi_t_j_tilde_k)\n",
    "            else:\n",
    "                pi_t_j_tilde.append(0)\n",
    "    else:\n",
    "        for k in range(len(beta_t)-1):\n",
    "            if(alpha_0_t_tilde>0):\n",
    "                pi_t_j_tilde_k=(1/alpha_0_t_tilde)*(alpha_0_t*beta_t[k]+Nu_t_j[k])\n",
    "                pi_t_j_tilde.append(pi_t_j_tilde_k)\n",
    "            else:\n",
    "                pi_t_j_tilde.append(0)\n",
    "    if(alpha_0_t_tilde>0):\n",
    "        pi_t_j_tilde_u=(1/alpha_0_t_tilde)*(alpha_0_t*beta_t[len(beta_t)-1])\n",
    "    else:pi_t_j_tilde_u=0\n",
    "    pi_t_j_tilde.append(pi_t_j_tilde_u)\n",
    "    return(pi_t_j_tilde)\n",
    "\n",
    "def compute_new_pi(alpha_0,v,beta,gamma,w,Nu):\n",
    "    pi_new=[]\n",
    "    alpha_tilde=compute_alpha_tilde(alpha_0,Nu)\n",
    "    for t in range(len(alpha_0)):\n",
    "        pi_new_t=[]\n",
    "        if(t==0): \n",
    "            for j in range(len(Nu[0])):\n",
    "                    pi_new_t_j_tilde=compute_pi_t_j_tilde(t,j,alpha_0[t],alpha_tilde[t][j],v[t],None,beta[t],Nu[t][j])\n",
    "                    params_dirich=alpha_tilde[t][j]*np.array(pi_new_t_j_tilde)\n",
    "                    pi_new_t_j=list(dirichlet_generate_random(params_dirich))\n",
    "                    pi_new_t.append(pi_new_t_j)\n",
    "        else:            \n",
    "            for j in range(len(Nu[0])):\n",
    "                    pi_new_t_j_tilde=compute_pi_t_j_tilde(t,j,alpha_0[t],alpha_tilde[t][j],v[t],pi_new[t-1][j],beta[t],Nu[t][j])\n",
    "                    params_dirich=alpha_tilde[t][j]*np.array(pi_new_t_j_tilde)\n",
    "                    pi_new_t_j=list(dirichlet_generate_random(params_dirich))\n",
    "                    pi_new_t.append(pi_new_t_j)\n",
    "        pi_new.append(pi_new_t)\n",
    "    return(pi_new)\n",
    "                    \n",
    "new_pi=compute_new_pi(alpha,v,beta,gamma,w,Nu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si on a plusieurs topics présents par corpus, cette fonction en extrait les plus fréquents. <br\\> Cette fonction permet de vérifier nos résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_best_topic_from_pi(N,average_phi):\n",
    "    bestAll=[]\n",
    "    for t in range(len(N)):\n",
    "        print(\"----- Temps {} -----:\".format(t)) \n",
    "        for j in range(len(N[t])):\n",
    "            print(\"Corpus {}:\".format(j))\n",
    "            best=np.argsort(-np.array(N[t][j]))\n",
    "            for i in range(5):\n",
    "                print(\"Topic #{}={} with {} docs \" .format(i,average_phi[best[i]],N[t][j][best[i]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "On **resample** chaque observation en suivant (20), (21) et l'information à posteriori donnée par (4.5). <br\\>\n",
    "En sortie, on a le topic le plus à même d'étre lié avec l'observation ainsi que la moyenne de chaque topic. \n",
    "En effet chaque: $\\phi_k \\sim Dir(param)$ où param est calculé à posteriori. La moyenne de chaque r.v. nous informe sur le topic et nous permet de faire des comparaisons avec les résultats obtenus en Table 2 de l'article.\n",
    "<br/> <br/>\n",
    "On peut calculer $$ P(z_{ji}^t=k / x_{ji}^t)\\sim P(z_{ji}^t=k/ \\pi_j^t).P(x_{ji}^t/ z_{ji}^t=k...)$$\n",
    "On sait que $$ P(z_{ji}^t=k/ \\pi_j^t) = \\pi_{jk}^t $$\n",
    "De plus, $$ P(x_{ji}^t/ z_{ji}^t=k...) = \\frac{\\Gamma(n+1) \\Gamma (\\sum_{a\\in A,w}^{W} X_{aw} +\\alpha_w)\n",
    " \\prod_{w=1}^{W} \\Gamma (\\alpha_w + x_{jiw}^t+ \\sum_{a\\in A} X_{aw}) }{\\Gamma (\\sum_{a\\in A,w}^{W} X_{aw} +\\alpha_w + x_{jiw}^t)  \\prod_{w=1}^{W} [\\Gamma ( x_{jiw}^t +1) \\Gamma (\\alpha_w + \\sum_{a\\in A} X_{aw}) ]} $$\n",
    "Avec $A = ((i,j,t),Z_{ji}^t=k)$\n",
    "<br/> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après normalisation des $P(z_{ji}^t=k / x_{ji}^t)$, on selectionne un nouveau topic pour chaque document. \n",
    "<br\\> On retourne aussi la moyenne des $\\phi_k \\sim Dir(\\alpha_1 + \\sum_{a\\in A} X_{a1},...,\\alpha_W + \\sum_{a\\in A} X_{aW}) $ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_new_z_i_j_t_egal_k(last_iteration,t,j,i,x_i_j_t,X,Z,pi_jt,W):\n",
    "    proba=[]\n",
    "    log_proba=[]\n",
    "    average_phi=[]\n",
    "    \n",
    "    Z_with_no_Xijt=copy.deepcopy(Z)\n",
    "    X_with_no_Xijt=copy.deepcopy(X)\n",
    "    del Z_with_no_Xijt[t][j][i]\n",
    "    del X_with_no_Xijt[t][j][i]\n",
    "    \n",
    "    for k,pi_jtk in enumerate(pi_jt):\n",
    "        average_phi_k=[]\n",
    "        flat_Z=[item for y in Z_with_no_Xijt for x in y for item in x]\n",
    "        flat_X=[item for y in X_with_no_Xijt for x in y for item in x]\n",
    "        Z_tij_k=[doc for doc,topic in zip(flat_X,flat_Z) if (topic==k)]\n",
    "        produit_numerateur=1\n",
    "        produit_denominateur_1=1\n",
    "        produit_denominateur_2=1\n",
    "        a=np.sum(Z_tij_k)\n",
    "        b=np.sum(x_i_j_t)\n",
    "        for w in range(W):\n",
    "            if(len(Z_tij_k)==0):\n",
    "                c=0\n",
    "            else:\n",
    "                c=np.sum(Z_tij_k,axis=0)[w] \n",
    "            if(last_iteration):\n",
    "                average_phi_k.append(((1/W)+c)/(1+a))\n",
    "            produit_numerateur+=gammaln(x_i_j_t[w]+(1/W)+c)\n",
    "            produit_denominateur_1+=gammaln((1/W)+c)\n",
    "            produit_denominateur_2+=gammaln(1+x_i_j_t[w])\n",
    "        log_proba.append(pi_jt[k]*mpmath.exp((gammaln(len(x_i_j_t)+1)+gammaln(a+1)+produit_numerateur)-(produit_denominateur_2+produit_denominateur_1+gammaln(a+b+1))))\n",
    "        average_phi.append(average_phi_k) \n",
    "    somme=sum(log_proba)\n",
    "    for k,pi_jtk in enumerate(pi_jt):\n",
    "        log_proba[k]=float(log_proba[k]/somme) \n",
    "    max_indice=np.random.choice(len(pi_jt),1,p=log_proba)  \n",
    "    return(max_indice,average_phi)\n",
    "#newZ=get_new_z_i_j_t_egal_k(1,0,0,0,data[0][0][0],data,Z,pi[0][0],W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On resample **toutes** les observations et on obtient les nouveaux N, qui sont les compteurs d'assignation aux topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_new_Z(data,pi,Z,W,K):\n",
    "    T=np.random.permutation(len(data))\n",
    "    for t in T:\n",
    "        J=np.random.permutation(len(data[t]))\n",
    "        print('Temps{}'.format(t))\n",
    "        for j in J:\n",
    "            I=np.random.permutation(len(data[t][j]))\n",
    "            for i in I:\n",
    "                if(t==(len(data)-1) and j==(len(data[t])-1) and i==(len(data[t][j])-1)):\n",
    "                    Z[t][j][i],average_phi=get_new_z_i_j_t_egal_k(1,t,j,i,data[t][j][i],data,Z,pi[t][j],W)\n",
    "                else:\n",
    "                    Z[t][j][i],unused_var=get_new_z_i_j_t_egal_k(0,t,j,i,data[t][j][i],data,Z,pi[t][j],W)\n",
    "    N=[]\n",
    "    for t in range(len(data)):\n",
    "        N_t=[]\n",
    "        for j in range(len(data[t])):\n",
    "                N_t.append(compute_n_t_j(K,Z[t][j]))\n",
    "        N.append(N_t)\n",
    "    return(Z,N,average_phi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALGORITHME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++ITERATION++++++: 0\n",
      "Temps3\n",
      "Temps0\n",
      "Temps1\n",
      "Temps2\n",
      "++++++ITERATION++++++: 1\n",
      "Temps1\n",
      "Temps3\n",
      "Temps2\n",
      "Temps0\n",
      "++++++ITERATION++++++: 2\n",
      "Temps0\n",
      "Temps1\n",
      "Temps3\n",
      "Temps2\n",
      "----- Temps 0 -----:\n",
      "Corpus 0:\n",
      "Topic #0=[0.1433531673513545, 0.8566468326486455] with 246 docs \n",
      "Topic #1=[0.2752992019568245, 0.7247007980431756] with 236 docs \n",
      "Topic #2=[0.3863023927794552, 0.6136976072205448] with 12 docs \n",
      "Topic #3=[0.38895061385478585, 0.6110493861452142] with 5 docs \n",
      "Topic #4=[0.389969728920785, 0.610030271079215] with 1 docs \n",
      "Corpus 1:\n",
      "Topic #0=[0.2752992019568245, 0.7247007980431756] with 134 docs \n",
      "Topic #1=[0.1433531673513545, 0.8566468326486455] with 38 docs \n",
      "Topic #2=[0.3863023927794552, 0.6136976072205448] with 35 docs \n",
      "Topic #3=[0.38960473620059205, 0.610395263799408] with 33 docs \n",
      "Topic #4=[0.389969728920785, 0.610030271079215] with 22 docs \n",
      "Corpus 2:\n",
      "Topic #0=[0.2752992019568245, 0.7247007980431756] with 110 docs \n",
      "Topic #1=[0.3722187963533941, 0.627781203646606] with 39 docs \n",
      "Topic #2=[0.38960473620059205, 0.610395263799408] with 28 docs \n",
      "Topic #3=[0.5259543271256425, 0.47404567287435745] with 28 docs \n",
      "Topic #4=[0.4700553733670233, 0.5299446266329767] with 24 docs \n",
      "----- Temps 1 -----:\n",
      "Corpus 0:\n",
      "Topic #0=[0.2752992019568245, 0.7247007980431756] with 255 docs \n",
      "Topic #1=[0.1433531673513545, 0.8566468326486455] with 58 docs \n",
      "Topic #2=[0.3722187963533941, 0.627781203646606] with 58 docs \n",
      "Topic #3=[0.38960473620059205, 0.610395263799408] with 52 docs \n",
      "Topic #4=[0.38895061385478585, 0.6110493861452142] with 28 docs \n",
      "Corpus 1:\n",
      "Topic #0=[0.2752992019568245, 0.7247007980431756] with 74 docs \n",
      "Topic #1=[0.3722187963533941, 0.627781203646606] with 63 docs \n",
      "Topic #2=[0.389969728920785, 0.610030271079215] with 29 docs \n",
      "Topic #3=[0.4204064352243861, 0.5795935647756139] with 25 docs \n",
      "Topic #4=[0.4816675153928059, 0.5183324846071942] with 21 docs \n",
      "Corpus 2:\n",
      "Topic #0=[0.5547242724492225, 0.44527572755077743] with 70 docs \n",
      "Topic #1=[0.6855089203490097, 0.3144910796509904] with 55 docs \n",
      "Topic #2=[0.4088429877278925, 0.5911570122721075] with 39 docs \n",
      "Topic #3=[0.4983206747834052, 0.5016793252165948] with 37 docs \n",
      "Topic #4=[0.5259543271256425, 0.47404567287435745] with 32 docs \n",
      "----- Temps 2 -----:\n",
      "Corpus 0:\n",
      "Topic #0=[0.2752992019568245, 0.7247007980431756] with 151 docs \n",
      "Topic #1=[0.3722187963533941, 0.627781203646606] with 57 docs \n",
      "Topic #2=[0.38960473620059205, 0.610395263799408] with 39 docs \n",
      "Topic #3=[0.3863023927794552, 0.6136976072205448] with 36 docs \n",
      "Topic #4=[0.4716869838773103, 0.5283130161226898] with 33 docs \n",
      "Corpus 1:\n",
      "Topic #0=[0.5522283067466072, 0.4477716932533928] with 62 docs \n",
      "Topic #1=[0.5358442290087088, 0.4641557709912913] with 45 docs \n",
      "Topic #2=[0.5259543271256425, 0.47404567287435745] with 25 docs \n",
      "Topic #3=[0.4204064352243861, 0.5795935647756139] with 24 docs \n",
      "Topic #4=[0.3722187963533941, 0.627781203646606] with 24 docs \n",
      "Corpus 2:\n",
      "Topic #0=[0.6855089203490097, 0.3144910796509904] with 187 docs \n",
      "Topic #1=[0.5547242724492225, 0.44527572755077743] with 80 docs \n",
      "Topic #2=[0.5358442290087088, 0.4641557709912913] with 42 docs \n",
      "Topic #3=[0.5522283067466072, 0.4477716932533928] with 25 docs \n",
      "Topic #4=[0.46199283217556747, 0.5380071678244326] with 18 docs \n",
      "----- Temps 3 -----:\n",
      "Corpus 0:\n",
      "Topic #0=[0.5547242724492225, 0.44527572755077743] with 63 docs \n",
      "Topic #1=[0.5522283067466072, 0.4477716932533928] with 59 docs \n",
      "Topic #2=[0.5358442290087088, 0.4641557709912913] with 53 docs \n",
      "Topic #3=[0.46199283217556747, 0.5380071678244326] with 44 docs \n",
      "Topic #4=[0.38960473620059205, 0.610395263799408] with 40 docs \n",
      "Corpus 1:\n",
      "Topic #0=[0.6855089203490097, 0.3144910796509904] with 148 docs \n",
      "Topic #1=[0.5522283067466072, 0.4477716932533928] with 62 docs \n",
      "Topic #2=[0.5358442290087088, 0.4641557709912913] with 40 docs \n",
      "Topic #3=[0.5547242724492225, 0.44527572755077743] with 33 docs \n",
      "Topic #4=[0.4716869838773103, 0.5283130161226898] with 13 docs \n",
      "Corpus 2:\n",
      "Topic #0=[0.6855089203490097, 0.3144910796509904] with 388 docs \n",
      "Topic #1=[0.5522283067466072, 0.4477716932533928] with 28 docs \n",
      "Topic #2=[0.5547242724492225, 0.44527572755077743] with 16 docs \n",
      "Topic #3=[0.5358442290087088, 0.4641557709912913] with 11 docs \n",
      "Topic #4=[0.5259543271256425, 0.47404567287435745] with 7 docs \n"
     ]
    }
   ],
   "source": [
    "def algo_evo_hdp(max_iter,corpora_sizes):\n",
    "    #----Create Data----#\n",
    "    true_phi=np.zeros((8,2))\n",
    "    true_phi[0]=[0.1,0.9]\n",
    "    true_phi[1]=[0.2,0.8]\n",
    "    true_phi[2]=[0.3,0.7]\n",
    "    true_phi[3]=[0.4,0.6]\n",
    "    true_phi[4]=[0.5,0.5]\n",
    "    true_phi[5]=[0.6,0.4]\n",
    "    true_phi[6]=[0.7,0.3]\n",
    "    true_phi[7]=[0.8,0.2]\n",
    "    T=4\n",
    "    J=3\n",
    "    W=2\n",
    "    K=20\n",
    "    info_data=local_components_and_corpora_sizes(T,J,corpora_sizes)    \n",
    "    data=generate_data_from_mixture_of_multinomials(T,J,info_data,true_phi) \n",
    "    #----Initialize Hyperparameters----#\n",
    "    a_xi=10\n",
    "    b_xi=1\n",
    "    xi=np.random.gamma(a_xi,b_xi)\n",
    "    a_gamma=10\n",
    "    b_gamma=1\n",
    "    a_alpha=10\n",
    "    b_alpha=1\n",
    "    gamma=[]\n",
    "    gamma=[np.random.gamma(a_gamma,b_gamma) for i in range(T)]\n",
    "    alpha=[]\n",
    "    alpha=[np.random.gamma(a_alpha,b_alpha) for i in range(T)]\n",
    "    v=T*[K*[0.5]]\n",
    "    w=T*[0.5]\n",
    "    #----Initialize parameters----#\n",
    "    params_loi_H=0.5\n",
    "    nu=stick_breaking(xi,K,W)\n",
    "    beta=initialize_G_0_t(gamma,nu,T,K,w)\n",
    "    pi=initialize_G_j_t(beta,alpha,J,T,K,v)\n",
    "    Z,N=randomly_assign_Z_initialisation(T,J,K,data)\n",
    "    #----Iterate Cascaded Gibbs Sampler----#\n",
    "    for i in range(max_iter):\n",
    "        print(\"++++++ITERATION++++++: {}\".format(i))\n",
    "        Tables,MetaTable,Tau,Nu=compute_Tables_Metatables(T,J,v,w,pi,beta,alpha,gamma,nu,N,K)\n",
    "        #on conserve seulement les topics qui ont été choisis pour décrire au moins un document.\n",
    "        M_k=np.sum(np.array(MetaTable)[:,:,2],axis=0)\n",
    "        M=np.sum(M_k)\n",
    "        liste_indice=np.nonzero(M_k)\n",
    "        M_k=M_k[M_k>0]\n",
    "        param_dir=list(M_k)\n",
    "        #on ajoute un topic pour l'itération suivante\n",
    "        param_dir.append(xi)\n",
    "        nu=dirichlet_generate_random(param_dir)\n",
    "        beta=compute_new_beta(gamma,w,nu,Tau)\n",
    "        pi=compute_new_pi(alpha,v,beta,gamma,w,Nu)\n",
    "        K=len(beta[0])\n",
    "        v=T*[K*[0.5]]\n",
    "        Z,N,average=get_new_Z(data,pi,Z,W,K)\n",
    "    #----Print Mean of topic and N----#\n",
    "        #print('---Beta=---:\\n{}'.format(beta))\n",
    "        #print('---Pi=---:\\n{}'.format(pi))\n",
    "        #print('---Average---=\\n{}\\n'.format(average)) \n",
    "        #print('---N---:\\n{}'.format(N))\n",
    "        if ((max_iter-1)==i):\n",
    "            get_best_topic_from_pi(N,average)\n",
    "        #print('---Tau---\\n{}'.format(Tau))\n",
    "        #print('---Nu---\\n{}'.format(Nu))\n",
    "        #print('---Tables---\\n{}'.format(Tables))\n",
    "        #print('---MetaTable---\\n{}'.format(MetaTable))\n",
    "max_iter=3 \n",
    "corpora_sizes=[[500,300,400],[510,320,430],[520,320,430],[530,340,450]]\n",
    "\n",
    "algo_evo_hdp(max_iter,corpora_sizes)   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les résultats sont donnés en Table 2. \n",
    "L'algorithme est très lent car l'optimisation est faîte par Gibbs Sampling. \n",
    "Après un nombre assez faible d'itération (environ 5), on retrouve les topics décrivant chacun des lots de données.\n",
    "Les résultats peuvent s'avérer approximatifs selon les paramètres donnés. \n",
    "\n",
    "**Points à améliorer :** <br\\>\n",
    "- Optimiser l'algorithme et le nombre de boucles\n",
    "- Tester le modèle avec un corpus de textes \n",
    "- Etudier les articles proposés par Nadi, plus récents et combinant réseaux de neuronnes et topic modelling."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
